import nltk
import spacy
import pandas as pd
import numpy as np
from textblob import TextBlob
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords

# ğŸ“Œ 1. Ã–rnek Metin
metin = "Merhaba bÃ¶cÃ¼cÃ¼ÄŸÃ¼m! BugÃ¼n doÄŸal dil iÅŸleme konusunu Ã¶ÄŸreneceÄŸiz. NLP Ã§ok gÃ¼Ã§lÃ¼ bir alandÄ±r."

# ğŸ“Œ 2. Tokenization (Kelime ve CÃ¼mle AyrÄ±ÅŸtÄ±rma)
nltk.download("punkt")
kelimeler = word_tokenize(metin)
cumleler = sent_tokenize(metin)

print("ğŸ”¹ Kelimeler:", kelimeler)
print("ğŸ”¹ CÃ¼mleler:", cumleler)

# ğŸ“Œ 3. Stopwords (Gereksiz Kelimeleri Ã‡Ä±karma)
nltk.download("stopwords")
stop_words = set(stopwords.words("turkish"))  # TÃ¼rkÃ§e stopwords kullanÄ±yoruz
temiz_kelime_listesi = [kelime for kelime in kelimeler if kelime.lower() not in stop_words]

print("ğŸ”¹ TemizlenmiÅŸ Kelimeler:", temiz_kelime_listesi)

# ğŸ“Œ 4. Lemmatization (Kelime KÃ¶kÃ¼ne Ä°ndirme)
nlp = spacy.load("en_core_web_sm")  # Ä°ngilizce iÃ§in, TÃ¼rkÃ§e destekli model yok
doc = nlp("running jumped eating cars mice")

kelime_kokleri = [token.lemma_ for token in doc]
print("ğŸ”¹ Lemmatization Sonucu:", kelime_kokleri)

# ğŸ“Œ 5. Duygu Analizi (Sentiment Analysis)
text_blob = TextBlob(metin)
print("ğŸ”¹ Duygu PuanÄ±:", text_blob.sentiment.polarity)  # -1 negatif, +1 pozitif

# ğŸ“Œ 6. Kelime FrekansÄ± Analizi
kelime_frekansi = pd.Series(temiz_kelime_listesi).value_counts()
print("ğŸ”¹ Kelime FrekanslarÄ±:\n", kelime_frekansi)

